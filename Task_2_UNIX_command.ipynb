{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## chapter2 : unix command"
      ],
      "metadata": {
        "id": "6AAPVeTpLefE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QLNlpQjSLdoS",
        "outputId": "b824ba93-2ddc-45fc-ccdf-ee2e6866fc0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-07-26 13:36:26--  https://nlp100.github.io/data/popular-names.txt\n",
            "Resolving nlp100.github.io (nlp100.github.io)... 185.199.108.153, 185.199.109.153, 185.199.110.153, ...\n",
            "Connecting to nlp100.github.io (nlp100.github.io)|185.199.108.153|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 55026 (54K) [text/plain]\n",
            "Saving to: ‘popular-names.txt’\n",
            "\n",
            "\rpopular-names.txt     0%[                    ]       0  --.-KB/s               \rpopular-names.txt   100%[===================>]  53.74K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2024-07-26 13:36:26 (4.24 MB/s) - ‘popular-names.txt’ saved [55026/55026]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://nlp100.github.io/data/popular-names.txt -O popular-names.txt\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Count the number of lines of the file. Confirm the result by using wc command."
      ],
      "metadata": {
        "id": "nSUhl13CN_Vj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wc -l popular-names.txt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_7fZmCfNnwO",
        "outputId": "a370aeca-3a14-4df3-af72-cb0064cd620b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2780 popular-names.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 11. Replace tabs into spaces\n",
        "Replace every occurrence of a tab character into a space. Confirm the result by using sed, tr, or expand command:"
      ],
      "metadata": {
        "id": "bMm3o_bIOHvG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sed 's/\\t/ /g' popular-names.txt > output.txt\n",
        "# or\n",
        "!tr '\\t' ' ' < popular-names.txt > output.txt\n",
        "# or\n",
        "!expand -t 1 popular-names.txt > output.txt\n"
      ],
      "metadata": {
        "id": "8tdELVetOMCX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 12. col1.txt from the first column, col2.txt from the second columnPermalink\n",
        "Extract the value of the first column of each line, and store the output into col1.txt. Extract the value of the second column of each line, and store the output into col2.txt. Confirm the result by using cut command."
      ],
      "metadata": {
        "id": "XQNUa4h4ORM2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cut -f 1 popular-names.txt > col1.txt\n",
        "!cut -f 2 popular-names.txt > col2.txt\n"
      ],
      "metadata": {
        "id": "sd2PhAPcOU--"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 13. Merging col1.txt and col2.txt\n",
        "Join the contents of col1.txt and col2.txt, and create a text file whose each line contains the values of the first and second columns (separated by tab character) of the original file. Confirm the result by using paste command."
      ],
      "metadata": {
        "id": "MJQIMY3iOlUN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!paste col1.txt col2.txt > merged.txt\n"
      ],
      "metadata": {
        "id": "qc3JpROfOmft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 14. First N lines\n",
        "Receive a natural number $N$ from a command-line argument, and output the first $N$ lines of the file. Confirm the result by using head command."
      ],
      "metadata": {
        "id": "xwmgv3YkOvWw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!head -n 5 popular-names.txt  # Replace 5 with  desired number of lines\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76cEeD9mO0MX",
        "outputId": "50796667-46d2-4472-ed5e-a1471ed474d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mary\tF\t7065\t1880\n",
            "Anna\tF\t2604\t1880\n",
            "Emma\tF\t2003\t1880\n",
            "Elizabeth\tF\t1939\t1880\n",
            "Minnie\tF\t1746\t1880\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 15. Last N linesPermalink\n",
        "Receive a natural number $N$ from a command-line argument, and output the last $N$ lines of the file. Confirm the result by using tail command"
      ],
      "metadata": {
        "id": "HW0H8uqBO5mm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!tail -n 5 popular-names.txt  # Replace 5 with  desired number of lines\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YD2IzMZyO-LH",
        "outputId": "7525c7f3-f7cb-4148-b856-7e0325bd0a53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Benjamin\tM\t13381\t2018\n",
            "Elijah\tM\t12886\t2018\n",
            "Lucas\tM\t12585\t2018\n",
            "Mason\tM\t12435\t2018\n",
            "Logan\tM\t12352\t2018\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 16. Split a file into N pieces\n",
        "Receive a natural number $N$ from a command-line argument, and split the input file into $N$ pieces at line boundaries. Confirm the result by using split command"
      ],
      "metadata": {
        "id": "1O-M7DyMPCgN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!split -n l/5 popular-names.txt popular-names_part  # Replace 5 with desired number of pieces\n"
      ],
      "metadata": {
        "id": "ZRyEn_OPPGMF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 17. Distinct strings in the first column\n",
        "Find distinct strings (a set of strings) of the first column of the file. Confirm the result by using cut, sort, and uniq commands."
      ],
      "metadata": {
        "id": "V-Zo2TQFPKZt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cut -f 1 popular-names.txt | sort | uniq\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x0B3qYmtPP1N",
        "outputId": "82471995-43b4-4740-e77a-6288c57896c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Abigail\n",
            "Aiden\n",
            "Alexander\n",
            "Alexis\n",
            "Alice\n",
            "Amanda\n",
            "Amelia\n",
            "Amy\n",
            "Andrew\n",
            "Angela\n",
            "Anna\n",
            "Annie\n",
            "Anthony\n",
            "Ashley\n",
            "Austin\n",
            "Ava\n",
            "Barbara\n",
            "Benjamin\n",
            "Bertha\n",
            "Bessie\n",
            "Betty\n",
            "Brandon\n",
            "Brian\n",
            "Brittany\n",
            "Carol\n",
            "Carolyn\n",
            "Charles\n",
            "Charlotte\n",
            "Chloe\n",
            "Christopher\n",
            "Clara\n",
            "Crystal\n",
            "Cynthia\n",
            "Daniel\n",
            "David\n",
            "Deborah\n",
            "Debra\n",
            "Donald\n",
            "Donna\n",
            "Doris\n",
            "Dorothy\n",
            "Edward\n",
            "Elijah\n",
            "Elizabeth\n",
            "Emily\n",
            "Emma\n",
            "Ethan\n",
            "Ethel\n",
            "Evelyn\n",
            "Florence\n",
            "Frances\n",
            "Frank\n",
            "Gary\n",
            "George\n",
            "Hannah\n",
            "Harper\n",
            "Harry\n",
            "Heather\n",
            "Helen\n",
            "Henry\n",
            "Ida\n",
            "Isabella\n",
            "Jacob\n",
            "James\n",
            "Jason\n",
            "Jayden\n",
            "Jeffrey\n",
            "Jennifer\n",
            "Jessica\n",
            "Joan\n",
            "John\n",
            "Joseph\n",
            "Joshua\n",
            "Judith\n",
            "Julie\n",
            "Justin\n",
            "Karen\n",
            "Kathleen\n",
            "Kelly\n",
            "Kimberly\n",
            "Larry\n",
            "Laura\n",
            "Lauren\n",
            "Liam\n",
            "Lillian\n",
            "Linda\n",
            "Lisa\n",
            "Logan\n",
            "Lori\n",
            "Lucas\n",
            "Madison\n",
            "Margaret\n",
            "Marie\n",
            "Mark\n",
            "Mary\n",
            "Mason\n",
            "Matthew\n",
            "Megan\n",
            "Melissa\n",
            "Mia\n",
            "Michael\n",
            "Michelle\n",
            "Mildred\n",
            "Minnie\n",
            "Nancy\n",
            "Nicholas\n",
            "Nicole\n",
            "Noah\n",
            "Oliver\n",
            "Olivia\n",
            "Pamela\n",
            "Patricia\n",
            "Rachel\n",
            "Rebecca\n",
            "Richard\n",
            "Robert\n",
            "Ronald\n",
            "Ruth\n",
            "Samantha\n",
            "Sandra\n",
            "Sarah\n",
            "Scott\n",
            "Sharon\n",
            "Shirley\n",
            "Sophia\n",
            "Stephanie\n",
            "Steven\n",
            "Susan\n",
            "Tammy\n",
            "Taylor\n",
            "Thomas\n",
            "Tracy\n",
            "Tyler\n",
            "Virginia\n",
            "Walter\n",
            "William\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 18. Sort lines in descending order of the third column\n",
        "Sort the lines in descending numeric order of the third column (sort lines without changing the content of each line). Confirm the result by using sort command."
      ],
      "metadata": {
        "id": "5iqYb_j8PZWe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sort -k 3,3nr popular-names.txt > sorted.txt\n"
      ],
      "metadata": {
        "id": "Kc5ADjg0PiTW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 19. Frequency of a string in the first column in descending order\n",
        "Find the frequency of a string in the first column, and sort the strings by descending order of their frequencies. Confirm the result by using cut, uniq, and sort commands."
      ],
      "metadata": {
        "id": "KBozipnyPntH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cut -f 1 popular-names.txt | sort | uniq -c | sort -k 1,1nr\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oAoQ0EJdPf3m",
        "outputId": "c827ff14-a53c-446f-8314-9cc411a0e9d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    118 James\n",
            "    111 William\n",
            "    108 John\n",
            "    108 Robert\n",
            "     92 Mary\n",
            "     75 Charles\n",
            "     74 Michael\n",
            "     73 Elizabeth\n",
            "     70 Joseph\n",
            "     60 Margaret\n",
            "     58 George\n",
            "     58 Thomas\n",
            "     57 David\n",
            "     51 Richard\n",
            "     45 Helen\n",
            "     43 Christopher\n",
            "     43 Frank\n",
            "     41 Anna\n",
            "     40 Edward\n",
            "     39 Ruth\n",
            "     38 Patricia\n",
            "     37 Matthew\n",
            "     36 Dorothy\n",
            "     35 Emma\n",
            "     32 Barbara\n",
            "     31 Daniel\n",
            "     31 Joshua\n",
            "     26 Emily\n",
            "     26 Jennifer\n",
            "     26 Linda\n",
            "     26 Sarah\n",
            "     25 Jacob\n",
            "     25 Jessica\n",
            "     24 Betty\n",
            "     24 Mildred\n",
            "     24 Susan\n",
            "     23 Ashley\n",
            "     23 Henry\n",
            "     22 Nancy\n",
            "     21 Andrew\n",
            "     20 Amanda\n",
            "     20 Donald\n",
            "     20 Florence\n",
            "     20 Marie\n",
            "     19 Samantha\n",
            "     18 Karen\n",
            "     18 Lisa\n",
            "     18 Madison\n",
            "     18 Melissa\n",
            "     18 Olivia\n",
            "     17 Abigail\n",
            "     17 Stephanie\n",
            "     16 Ethel\n",
            "     16 Mark\n",
            "     16 Sandra\n",
            "     15 Angela\n",
            "     15 Carol\n",
            "     15 Ethan\n",
            "     15 Frances\n",
            "     15 Heather\n",
            "     15 Isabella\n",
            "     15 Michelle\n",
            "     14 Amy\n",
            "     14 Ava\n",
            "     14 Kimberly\n",
            "     14 Shirley\n",
            "     13 Brian\n",
            "     13 Deborah\n",
            "     13 Hannah\n",
            "     13 Jason\n",
            "     13 Nicole\n",
            "     13 Sophia\n",
            "     13 Virginia\n",
            "     12 Bertha\n",
            "     12 Donna\n",
            "     12 Minnie\n",
            "     11 Cynthia\n",
            "     10 Alice\n",
            "     10 Brittany\n",
            "     10 Doris\n",
            "     10 Mia\n",
            "     10 Nicholas\n",
            "     10 Noah\n",
            "     10 Ronald\n",
            "      9 Debra\n",
            "      9 Joan\n",
            "      9 Tyler\n",
            "      8 Alexander\n",
            "      8 Alexis\n",
            "      8 Clara\n",
            "      8 Ida\n",
            "      8 Judith\n",
            "      8 Mason\n",
            "      8 Taylor\n",
            "      7 Brandon\n",
            "      7 Harry\n",
            "      7 Liam\n",
            "      7 Sharon\n",
            "      7 Steven\n",
            "      7 Tammy\n",
            "      6 Anthony\n",
            "      5 Annie\n",
            "      5 Charlotte\n",
            "      5 Gary\n",
            "      5 Jayden\n",
            "      5 Jeffrey\n",
            "      4 Austin\n",
            "      4 Benjamin\n",
            "      4 Chloe\n",
            "      4 Justin\n",
            "      4 Kathleen\n",
            "      4 Lillian\n",
            "      3 Aiden\n",
            "      3 Elijah\n",
            "      3 Evelyn\n",
            "      3 Harper\n",
            "      3 Megan\n",
            "      2 Amelia\n",
            "      2 Bessie\n",
            "      2 Larry\n",
            "      2 Lauren\n",
            "      2 Logan\n",
            "      2 Oliver\n",
            "      2 Rebecca\n",
            "      1 Carolyn\n",
            "      1 Crystal\n",
            "      1 Julie\n",
            "      1 Kelly\n",
            "      1 Laura\n",
            "      1 Lori\n",
            "      1 Lucas\n",
            "      1 Pamela\n",
            "      1 Rachel\n",
            "      1 Scott\n",
            "      1 Tracy\n",
            "      1 Walter\n"
          ]
        }
      ]
    }
  ]
}